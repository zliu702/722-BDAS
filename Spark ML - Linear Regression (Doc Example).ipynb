{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression (Documentation Example)\n",
    "\n",
    "The documentation example is available here: https://spark.apache.org/docs/2.1.1/ml-classification-regression.html#linear-regression.\n",
    "\n",
    "Objective: The goal of this tutorial is to get you used to reading documentation, understanding it, and then applying it. The dataset is quite unrealistic, but it is useful in understanding the basic elements of Spark's MLlib library. More relevant datasets are used in the Advanced Linear Regression exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section must be included at the beginning of each new notebook. Remember to change the app name.\n",
    "# If you're using VirtualBox, change the below to '/home/user/spark-2.1.1-bin-hadoop2.7'\n",
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('linear_regression_docs').getOrCreate()\n",
    "\n",
    "# If you're getting an error with numpy, please type 'sudo pip3 install numpy --user' into the console.\n",
    "# If you're getting an error with another package, type 'sudo pip3 install PACKAGENAME --user'. \n",
    "# Replace PACKAGENAME with the relevant package (such as pandas, etc).\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model training data. Location of the data may be different.\n",
    "training = spark.read.format(\"libsvm\").load(\"Datasets/sample_linear_regression_data.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The libsvm format might be new to you. It's not used often, and may not be relevant to your dataset. However, it's used extensively throughout the Spark documentation. Let's see what the training data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "|              label|            features|\n",
      "+-------------------+--------------------+\n",
      "| -9.490009878824548|(10,[0,1,2,3,4,5,...|\n",
      "| 0.2577820163584905|(10,[0,1,2,3,4,5,...|\n",
      "| -4.438869807456516|(10,[0,1,2,3,4,5,...|\n",
      "|-19.782762789614537|(10,[0,1,2,3,4,5,...|\n",
      "| -7.966593841555266|(10,[0,1,2,3,4,5,...|\n",
      "| -7.896274316726144|(10,[0,1,2,3,4,5,...|\n",
      "| -8.464803554195287|(10,[0,1,2,3,4,5,...|\n",
      "| 2.1214592666251364|(10,[0,1,2,3,4,5,...|\n",
      "| 1.0720117616524107|(10,[0,1,2,3,4,5,...|\n",
      "|-13.772441561702871|(10,[0,1,2,3,4,5,...|\n",
      "| -5.082010756207233|(10,[0,1,2,3,4,5,...|\n",
      "|  7.887786536531237|(10,[0,1,2,3,4,5,...|\n",
      "| 14.323146365332388|(10,[0,1,2,3,4,5,...|\n",
      "|-20.057482615789212|(10,[0,1,2,3,4,5,...|\n",
      "|-0.8995693247765151|(10,[0,1,2,3,4,5,...|\n",
      "| -19.16829262296376|(10,[0,1,2,3,4,5,...|\n",
      "|  5.601801561245534|(10,[0,1,2,3,4,5,...|\n",
      "|-3.2256352187273354|(10,[0,1,2,3,4,5,...|\n",
      "| 1.5299675726687754|(10,[0,1,2,3,4,5,...|\n",
      "| -0.250102447941961|(10,[0,1,2,3,4,5,...|\n",
      "+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualise the training data format.\n",
    "training.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the data format that Spark needs to run a machine learning algorithm. One column with the name \"label\" and the other with the name \"features\". The label represents the output/answer/predictor (for example, house value), while the features represent the inputs (for example, number of rooms/number of bathrooms/etc). \n",
    "\n",
    "The \"label\" column then needs to have the numerical label, either a regression/classification numerical value. It will not accept raw text. \n",
    "\n",
    "The features column is a vector of all the features that belong to that row. Usually what we end up doing is combining the various feature columns we have into a single 'features' column using various data transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the default values:\n",
    "# featuresCol: What is the features column named? \n",
    "# labelCol: What is the label column named?\n",
    "lr = LinearRegression(featuresCol='features', labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit/train the model. Fit the model using the training data. Note that there is no training/testing split so far.\n",
    "lrModel = lr.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the summary attribute to get even more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.0073350710225801715,0.8313757584337543,-0.8095307954684084,2.441191686884721,0.5191713795290003,1.1534591903547016,-0.2989124112808717,-0.5128514186201779,-0.619712827067017,0.6956151804322931]\n",
      "Intercept: 0.14228558260358093\n",
      "+-------------------+\n",
      "|          residuals|\n",
      "+-------------------+\n",
      "|-11.011130022096554|\n",
      "| 0.9236590911176538|\n",
      "|-4.5957401897776675|\n",
      "|  -20.4201774575836|\n",
      "|-10.339160314788181|\n",
      "|-5.9552091439610555|\n",
      "|-10.726906349283922|\n",
      "|  2.122807193191233|\n",
      "|  4.077122222293811|\n",
      "|-17.316168071241652|\n",
      "| -4.593044343959059|\n",
      "|  6.380476690746936|\n",
      "| 11.320566035059846|\n",
      "|-20.721971774534094|\n",
      "| -2.736692773777401|\n",
      "| -16.66886934252847|\n",
      "|  8.242186378876315|\n",
      "|-1.3723486332690233|\n",
      "|-0.7060332131264666|\n",
      "|-1.1591135969994064|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "RMSE: 10.16309157133015\n",
      "R2: 0.027839179518600154\n"
     ]
    }
   ],
   "source": [
    "# Summarize the model over the training set and print out some metrics.\n",
    "trainingSummary = lrModel.summary\n",
    "\n",
    "# Let's see some examples from the documentation:\n",
    "print(\"Coefficients: \" + str(lrModel.coefficients))\n",
    "print(\"Intercept: \" + str(lrModel.intercept))\n",
    "\n",
    "# There is some other, potentially more interesting, information that we can see.\n",
    "trainingSummary.residuals.show()\n",
    "\n",
    "# Print Root Mean Squared Error. \n",
    "print(\"RMSE: {}\".format(trainingSummary.rootMeanSquaredError))\n",
    "\n",
    "# Print R-Squared.\n",
    "print(\"R2: {}\".format(trainingSummary.r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Splits\n",
    "\n",
    "Based on our nine-step process, we've actually missed a fundamental step following the Spark documentation! We never split our data into a training and testing set. Instead we've trained the model using all of our data, which you know by now is not a good idea.\n",
    "\n",
    "Luckily, Spark DataFrames has a convienent method of splitting the data. Let's see it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember, data is stored in the parent directory. \n",
    "all_data = spark.read.format(\"libsvm\").load(\"Datasets/sample_linear_regression_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass in the split between training/test as a list.\n",
    "# This is based on your test designs, but generally 70/30 or 60/40 splits are used. In your assignments, you should justify why/which split you used. \n",
    "train_data,test_data = all_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "|              label|            features|\n",
      "+-------------------+--------------------+\n",
      "|-28.046018037776633|(10,[0,1,2,3,4,5,...|\n",
      "|-26.805483428483072|(10,[0,1,2,3,4,5,...|\n",
      "|-26.736207182601724|(10,[0,1,2,3,4,5,...|\n",
      "|-23.487440120936512|(10,[0,1,2,3,4,5,...|\n",
      "|-22.949825936196074|(10,[0,1,2,3,4,5,...|\n",
      "|-21.432387764165806|(10,[0,1,2,3,4,5,...|\n",
      "|-20.212077258958672|(10,[0,1,2,3,4,5,...|\n",
      "|-20.057482615789212|(10,[0,1,2,3,4,5,...|\n",
      "|-19.884560774273424|(10,[0,1,2,3,4,5,...|\n",
      "|-19.872991038068406|(10,[0,1,2,3,4,5,...|\n",
      "|-19.402336030214553|(10,[0,1,2,3,4,5,...|\n",
      "|-18.845922472898582|(10,[0,1,2,3,4,5,...|\n",
      "| -18.27521356600463|(10,[0,1,2,3,4,5,...|\n",
      "|-17.803626188664516|(10,[0,1,2,3,4,5,...|\n",
      "|-17.428674570939506|(10,[0,1,2,3,4,5,...|\n",
      "|-17.065399625876015|(10,[0,1,2,3,4,5,...|\n",
      "| -16.71909683360509|(10,[0,1,2,3,4,5,...|\n",
      "|-16.692207021311106|(10,[0,1,2,3,4,5,...|\n",
      "| -16.26143027545273|(10,[0,1,2,3,4,5,...|\n",
      "|-16.151349351277112|(10,[0,1,2,3,4,5,...|\n",
      "+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+-------------------+\n",
      "|summary|              label|\n",
      "+-------+-------------------+\n",
      "|  count|                338|\n",
      "|   mean|0.46205619375605145|\n",
      "| stddev| 10.333920610318849|\n",
      "|    min|-28.046018037776633|\n",
      "|    max|  27.78383192005107|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's check out our training data.\n",
    "train_data.show()\n",
    "\n",
    "# Let's check out the count.\n",
    "train_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "|              label|            features|\n",
      "+-------------------+--------------------+\n",
      "|-28.571478869743427|(10,[0,1,2,3,4,5,...|\n",
      "| -23.51088409032297|(10,[0,1,2,3,4,5,...|\n",
      "|-22.837460416919342|(10,[0,1,2,3,4,5,...|\n",
      "|-19.782762789614537|(10,[0,1,2,3,4,5,...|\n",
      "| -19.66731861537172|(10,[0,1,2,3,4,5,...|\n",
      "| -19.16829262296376|(10,[0,1,2,3,4,5,...|\n",
      "|-17.494200356883344|(10,[0,1,2,3,4,5,...|\n",
      "| -17.32672073267595|(10,[0,1,2,3,4,5,...|\n",
      "|-17.026492264209548|(10,[0,1,2,3,4,5,...|\n",
      "| -16.08565904102149|(10,[0,1,2,3,4,5,...|\n",
      "|-15.437384793431217|(10,[0,1,2,3,4,5,...|\n",
      "|-15.310980589416289|(10,[0,1,2,3,4,5,...|\n",
      "|-15.056482974542433|(10,[0,1,2,3,4,5,...|\n",
      "|-14.822152909751189|(10,[0,1,2,3,4,5,...|\n",
      "|-14.762758252931127|(10,[0,1,2,3,4,5,...|\n",
      "|-13.420594775890757|(10,[0,1,2,3,4,5,...|\n",
      "| -13.15333560636553|(10,[0,1,2,3,4,5,...|\n",
      "|-13.039928064104615|(10,[0,1,2,3,4,5,...|\n",
      "|-12.558575788856189|(10,[0,1,2,3,4,5,...|\n",
      "|-12.491442077546413|(10,[0,1,2,3,4,5,...|\n",
      "+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+--------------------+\n",
      "|summary|               label|\n",
      "+-------+--------------------+\n",
      "|  count|                 163|\n",
      "|   mean|-0.16855026729972847|\n",
      "| stddev|  10.303251800605551|\n",
      "|    min| -28.571478869743427|\n",
      "|    max|  27.111027963108548|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# And our test data. \n",
    "test_data.show()\n",
    "\n",
    "# Let's check out the count. Note an approximate 70/30 split between the data points. \n",
    "test_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|          residuals|\n",
      "+-------------------+\n",
      "| -28.37000724264714|\n",
      "|-23.918618630174038|\n",
      "| -21.84981668068578|\n",
      "|-21.312278157292983|\n",
      "|-20.974738771352886|\n",
      "| -18.36927256990435|\n",
      "| -16.95657277795182|\n",
      "| -18.08354648180465|\n",
      "|  -16.5319038916002|\n",
      "|-15.860687227428382|\n",
      "|-13.835390248758486|\n",
      "|-13.695956096252058|\n",
      "|-16.750872747750275|\n",
      "|-16.362961040929086|\n",
      "| -15.62218086750222|\n",
      "|-13.764319475272401|\n",
      "|-12.524206065985137|\n",
      "|-13.061198558699573|\n",
      "|-13.456697944360819|\n",
      "|-14.126901094332979|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "RMSE: 10.195829671927767\n"
     ]
    }
   ],
   "source": [
    "# Now we train the model using train_data (not all data).\n",
    "correct_model = lr.fit(train_data)\n",
    "\n",
    "# Now we can directly get a summary object using the evaluate method.\n",
    "test_results = correct_model.evaluate(test_data)\n",
    "\n",
    "# And generate some basic evaluation metrics. \n",
    "test_results.residuals.show()\n",
    "print(\"RMSE: {}\".format(test_results.rootMeanSquaredError))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out a few different evaluation metrics applicable to regression models:\n",
    "\n",
    "Mean Absolute Error - Average of the error between the true value and predicted value. For example, if you're trying to predict housing price, MAE allows you to state that 'on average your model is off by $100,000 on average per house'.\n",
    "\n",
    "Mean Squared Error - Instead of taking the absolute error value, the errors are now squared. If you have a large difference between your predicted value and your true value, that difference becomes even more prominent when you square it. This makes it easier to notice when your model is off by a significantly large margin. However, the problem with MSE is that the units are now different. Instead of a $100k housing price error, the error is now 100k squared.\n",
    "\n",
    "Root Mean Absolute Error - So what do you do? Take the root of MSE (RMAE) to convert it back into the original unit. This retains the enhanced difference on significantly large errors as well maintains the appropriate unit. Because of this, this metric is the most popular. \n",
    "\n",
    "R2 (aka Coefficient of Determination) - This measures the amount of variance your model can explain (between 0 and 100%), but does not tell the entire story. It's not actually an evaluation metric, but more of a statistical measure of your model. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
