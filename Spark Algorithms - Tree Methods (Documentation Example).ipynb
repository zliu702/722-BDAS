{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Methods (Documentation Example)\n",
    "\n",
    "This is just a quick walkthrough of the Documentation's Example of Random Forest.\n",
    "\n",
    "Remember, you can use tree methods for both regression and classification problems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must be included at the beginning of each new notebook. Remember to change the app name.\n",
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('tree_methods_doc').getOrCreate()\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import (RandomForestClassifier, GBTClassifier, DecisionTreeClassifier)\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and parse the data file, converting it to a DataFrame.\n",
    "data = spark.read.format(\"libsvm\").load(\"Datasets/sample_libsvm_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "|  1.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[151,152,153...|\n",
      "|  0.0|(692,[129,130,131...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[99,100,101,...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[153,154,155...|\n",
      "|  0.0|(692,[151,152,153...|\n",
      "|  1.0|(692,[129,130,131...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  1.0|(692,[150,151,152...|\n",
      "|  0.0|(692,[124,125,126...|\n",
      "|  0.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[97,98,99,12...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's get a better look at the data.\n",
    "data.show()\n",
    "\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (30% held out for testing).\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all three models. Note the number of trees. \n",
    "# The more trees you have, the more computation time. But this could also significantly increase accuracy. So there's a tradeoff. \n",
    "dt = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model. \n",
    "model_rf = rf.fit(trainingData)\n",
    "model_dt = dt.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's do the transformation.\n",
    "prediction_rf = model_rf.transform(testData)\n",
    "prediction_dt = model_dt.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-------------+-----------+----------+\n",
      "|label|            features|rawPrediction|probability|prediction|\n",
      "+-----+--------------------+-------------+-----------+----------+\n",
      "|  0.0|(692,[121,122,123...|   [20.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[122,123,124...|   [20.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[123,124,125...|   [19.0,1.0]|[0.95,0.05]|       0.0|\n",
      "|  0.0|(692,[123,124,125...|   [20.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[124,125,126...|   [20.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[124,125,126...|   [20.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[124,125,126...|   [19.0,1.0]|[0.95,0.05]|       0.0|\n",
      "|  0.0|(692,[126,127,128...|   [19.0,1.0]|[0.95,0.05]|       0.0|\n",
      "|  0.0|(692,[126,127,128...|   [20.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[126,127,128...|   [20.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[126,127,128...|   [19.0,1.0]|[0.95,0.05]|       0.0|\n",
      "|  0.0|(692,[126,127,128...|   [20.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[126,127,128...|   [20.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[151,152,153...|   [20.0,0.0]|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[152,153,154...|   [19.0,1.0]|[0.95,0.05]|       0.0|\n",
      "|  0.0|(692,[153,154,155...|   [18.0,2.0]|  [0.9,0.1]|       0.0|\n",
      "|  0.0|(692,[234,235,237...|   [18.0,2.0]|  [0.9,0.1]|       0.0|\n",
      "|  1.0|(692,[123,124,125...|   [1.0,19.0]|[0.05,0.95]|       1.0|\n",
      "|  1.0|(692,[124,125,126...|   [1.0,19.0]|[0.05,0.95]|       1.0|\n",
      "|  1.0|(692,[124,125,126...|   [0.0,20.0]|  [0.0,1.0]|       1.0|\n",
      "+-----+--------------------+-------------+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's have a look at the first one. \n",
    "prediction_rf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+\n",
      "|prediction|label|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       0.0|  0.0|(692,[121,122,123...|\n",
      "|       0.0|  0.0|(692,[122,123,124...|\n",
      "|       0.0|  0.0|(692,[123,124,125...|\n",
      "|       0.0|  0.0|(692,[123,124,125...|\n",
      "|       0.0|  0.0|(692,[124,125,126...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select example rows to display.\n",
    "prediction_rf.select(\"prediction\", \"label\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select (prediction, true label) and compute test error.\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0\n"
     ]
    }
   ],
   "source": [
    "# A test error of zero means that the model accuracy is at 100%. \n",
    "# In most cases this is unrealistic, but here it's correct due to the simple data used in the documentation.\n",
    "accuracy = evaluator.evaluate(prediction_rf)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Trees\n",
    "\n",
    "Gradient-boosted trees (GBTs) are a popular classification and regression method using ensembles of decision trees. More information about the spark.ml implementation can be found further in the section on [GBTs](http://spark.apache.org/docs/latest/ml-classification-regression.html#gradient-boosted-trees-gbts). For more information on the algorithm itself, please see the [spark.mllib documentation on GBTs.](http://spark.apache.org/docs/latest/mllib-ensembles.html#gradient-boosted-trees-gbts)\n",
    "\n",
    "Luckily Spark makes very easy to use, basically just an import switch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+\n",
      "|prediction|label|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       1.0|  0.0|(692,[98,99,100,1...|\n",
      "|       0.0|  0.0|(692,[122,123,148...|\n",
      "|       0.0|  0.0|(692,[124,125,126...|\n",
      "|       0.0|  0.0|(692,[124,125,126...|\n",
      "|       0.0|  0.0|(692,[124,125,126...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "# Load and parse the data file, converting it to a DataFrame.\n",
    "data = spark.read.format(\"libsvm\").load(\"Datasets/sample_libsvm_data.txt\")\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing).\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a GBT model.\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\", maxIter=10)\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = gbt.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.0645161\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move on to a more realistic example!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
