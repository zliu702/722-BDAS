{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark ML - Linear Regression (Adv Example)\n",
    "Now that you've completed the documentation example, it's good to go through something a little more complex. This tutorial's materials have been adapted from Susan Li. Find more information here: \n",
    "- https://towardsdatascience.com/building-a-linear-regression-with-pyspark-and-mllib-d065c3ba246a\n",
    "- https://github.com/susanli2016/PySpark-and-MLlib.\n",
    "\n",
    "Objective: We're using a dataset from Kaggle to predict housing prices in Boston. We'll explore the data, visualise it, create a vector, build a regression model and evaluate it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section must be included at the beginning of each new notebook. Remember to change the app name.\n",
    "# If you're using VirtualBox, change the below to '/home/user/spark-2.1.1-bin-hadoop2.7'\n",
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('linear_regression_adv').getOrCreate()\n",
    "\n",
    "# If you're getting an error with numpy, please type 'sudo pip3 install numpy --user' into the console.\n",
    "# If you're getting an error with another package, type 'sudo pip3 install PACKAGENAME --user'. \n",
    "# Replace PACKAGENAME with the relevant package (such as pandas, etc).\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# First, let's import the data. Note that we can infer the schema as it's a CSV file.\n",
    "df = spark.read.csv(\"Datasets/boston_housing_data.csv\",inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(crim=0.00632, zn=18.0, indus=2.31, chas=0, nox=0.538, rm=6.575, age=65.2, dis=4.09, rad=1, tax=296, ptratio=15.3, b=396.9, lstat=4.98, medv=24.0)\n",
      "root\n",
      " |-- crim: double (nullable = true)\n",
      " |-- zn: double (nullable = true)\n",
      " |-- indus: double (nullable = true)\n",
      " |-- chas: integer (nullable = true)\n",
      " |-- nox: double (nullable = true)\n",
      " |-- rm: double (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- dis: double (nullable = true)\n",
      " |-- rad: integer (nullable = true)\n",
      " |-- tax: integer (nullable = true)\n",
      " |-- ptratio: double (nullable = true)\n",
      " |-- b: double (nullable = true)\n",
      " |-- lstat: double (nullable = true)\n",
      " |-- medv: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's explore. Here's the first row of the data.\n",
    "print(df.head())\n",
    "\n",
    "# And the entire data structure. \n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Information\n",
    "- CRIM — per capita crime rate by town.\n",
    "- ZN — proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "- INDUS — proportion of non-retail business acres per town.\n",
    "- CHAS — Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).\n",
    "- NOX — nitrogen oxides concentration (parts per 10 million).\n",
    "- RM — average number of rooms per dwelling.\n",
    "- AGE — proportion of owner-occupied units built prior to 1940.\n",
    "- DIS — weighted mean of distances to five Boston employment centres.\n",
    "- RAD — index of accessibility to radial highways.\n",
    "- TAX — full-value property-tax rate per \\$10,000.\n",
    "- PTRATIO — pupil-teacher ratio by town.\n",
    "- BLACK — 1000(Bk — 0.63)² where Bk is the proportion of blacks by town.\n",
    "- LSTAT — lower status of the population (percent).\n",
    "- MEDV — median value of owner-occupied homes in $1000s. This is the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>count</td>\n",
       "      <td>mean</td>\n",
       "      <td>stddev</td>\n",
       "      <td>min</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crim</th>\n",
       "      <td>506</td>\n",
       "      <td>3.6135235573122535</td>\n",
       "      <td>8.601545105332491</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>88.9762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zn</th>\n",
       "      <td>506</td>\n",
       "      <td>11.363636363636363</td>\n",
       "      <td>23.32245299451514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indus</th>\n",
       "      <td>506</td>\n",
       "      <td>11.136778656126504</td>\n",
       "      <td>6.860352940897589</td>\n",
       "      <td>0.46</td>\n",
       "      <td>27.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chas</th>\n",
       "      <td>506</td>\n",
       "      <td>0.0691699604743083</td>\n",
       "      <td>0.2539940413404101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nox</th>\n",
       "      <td>506</td>\n",
       "      <td>0.5546950592885372</td>\n",
       "      <td>0.11587767566755584</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rm</th>\n",
       "      <td>506</td>\n",
       "      <td>6.284634387351787</td>\n",
       "      <td>0.7026171434153232</td>\n",
       "      <td>3.561</td>\n",
       "      <td>8.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>506</td>\n",
       "      <td>68.57490118577078</td>\n",
       "      <td>28.148861406903595</td>\n",
       "      <td>2.9</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dis</th>\n",
       "      <td>506</td>\n",
       "      <td>3.795042687747034</td>\n",
       "      <td>2.10571012662761</td>\n",
       "      <td>1.1296</td>\n",
       "      <td>12.1265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rad</th>\n",
       "      <td>506</td>\n",
       "      <td>9.549407114624506</td>\n",
       "      <td>8.707259384239366</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tax</th>\n",
       "      <td>506</td>\n",
       "      <td>408.2371541501976</td>\n",
       "      <td>168.53711605495903</td>\n",
       "      <td>187</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ptratio</th>\n",
       "      <td>506</td>\n",
       "      <td>18.455533596837967</td>\n",
       "      <td>2.1649455237144455</td>\n",
       "      <td>12.6</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>506</td>\n",
       "      <td>356.67403162055257</td>\n",
       "      <td>91.29486438415782</td>\n",
       "      <td>0.32</td>\n",
       "      <td>396.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lstat</th>\n",
       "      <td>506</td>\n",
       "      <td>12.653063241106723</td>\n",
       "      <td>7.141061511348571</td>\n",
       "      <td>1.73</td>\n",
       "      <td>37.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medv</th>\n",
       "      <td>506</td>\n",
       "      <td>22.532806324110698</td>\n",
       "      <td>9.197104087379815</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0                   1                    2        3        4\n",
       "summary  count                mean               stddev      min      max\n",
       "crim       506  3.6135235573122535    8.601545105332491  0.00632  88.9762\n",
       "zn         506  11.363636363636363    23.32245299451514      0.0    100.0\n",
       "indus      506  11.136778656126504    6.860352940897589     0.46    27.74\n",
       "chas       506  0.0691699604743083   0.2539940413404101        0        1\n",
       "nox        506  0.5546950592885372  0.11587767566755584    0.385    0.871\n",
       "rm         506   6.284634387351787   0.7026171434153232    3.561     8.78\n",
       "age        506   68.57490118577078   28.148861406903595      2.9    100.0\n",
       "dis        506   3.795042687747034     2.10571012662761   1.1296  12.1265\n",
       "rad        506   9.549407114624506    8.707259384239366        1       24\n",
       "tax        506   408.2371541501976   168.53711605495903      187      711\n",
       "ptratio    506  18.455533596837967   2.1649455237144455     12.6     22.0\n",
       "b          506  356.67403162055257    91.29486438415782     0.32    396.9\n",
       "lstat      506  12.653063241106723    7.141061511348571     1.73    37.97\n",
       "medv       506  22.532806324110698    9.197104087379815      5.0     50.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that we understand the data's features, let's use a Python package to neatly describe the data.\n",
    "import pandas as pd\n",
    "df.describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up a DataFrame for Machine Learning (MLlib)\n",
    "We need to do a few things before Spark can accept this data for machine learning. First of all, it needs to be in the form of two columns: label and features. Unlike the documentation example, this data is messy. We'll need to combine all of the features into a single vector. VectorAssembler simplifies the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- crim: double (nullable = true)\n",
      " |-- zn: double (nullable = true)\n",
      " |-- indus: double (nullable = true)\n",
      " |-- chas: integer (nullable = true)\n",
      " |-- nox: double (nullable = true)\n",
      " |-- rm: double (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- dis: double (nullable = true)\n",
      " |-- rad: integer (nullable = true)\n",
      " |-- tax: integer (nullable = true)\n",
      " |-- ptratio: double (nullable = true)\n",
      " |-- b: double (nullable = true)\n",
      " |-- lstat: double (nullable = true)\n",
      " |-- medv: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(crim=0.00632, zn=18.0, indus=2.31, chas=0, nox=0.538, rm=6.575, age=65.2, dis=4.09, rad=1, tax=296, ptratio=15.3, b=396.9, lstat=4.98, medv=24.0, features=DenseVector([0.0063, 18.0, 2.31, 0.0, 0.538, 6.575, 65.2, 4.09, 1.0, 296.0, 15.3, 396.9, 4.98]))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import VectorAssembler and Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# The input columns are the feature column names, and the output column is what you'd like the new column to be named. \n",
    "vector_assembler = VectorAssembler(inputCols = ['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'b', 'lstat'], outputCol = 'features')\n",
    "\n",
    "# Now that we've created the assembler variable, let's actually transform the data.\n",
    "vector_output = vector_assembler.transform(df)\n",
    "\n",
    "# Using print schema, you see that the features output column has been added. \n",
    "vector_output.printSchema()\n",
    "\n",
    "# You can see that the features column is a DenseVector that combines the various features as expected.\n",
    "vector_output.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(features=DenseVector([0.0063, 18.0, 2.31, 0.0, 0.538, 6.575, 65.2, 4.09, 1.0, 296.0, 15.3, 396.9, 4.98]), medv=24.0)]\n",
      "+--------------------+----+\n",
      "|            features|medv|\n",
      "+--------------------+----+\n",
      "|[0.00632,18.0,2.3...|24.0|\n",
      "|[0.02731,0.0,7.07...|21.6|\n",
      "|[0.02729,0.0,7.07...|34.7|\n",
      "+--------------------+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Because the features have been combined into one vector, we no longer need them. Below we select the features and label.\n",
    "vector_output = vector_output.select(['features', 'medv'])\n",
    "\n",
    "# You can see that the dataframe now only contains two columns. \n",
    "print(vector_output.head(1))\n",
    "vector_output.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|              medv|\n",
      "+-------+------------------+\n",
      "|  count|               347|\n",
      "|   mean|22.520461095100888|\n",
      "| stddev| 9.055746543025418|\n",
      "|    min|               5.0|\n",
      "|    max|              50.0|\n",
      "+-------+------------------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|              medv|\n",
      "+-------+------------------+\n",
      "|  count|               159|\n",
      "|   mean|22.559748427672957|\n",
      "| stddev| 9.527396336301386|\n",
      "|    min|               5.0|\n",
      "|    max|              50.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's do a randomised 70/30 split. Remember, you should explain why you chose a particular split. \n",
    "train_data,test_data = vector_output.randomSplit([0.7,0.3])\n",
    "\n",
    "# Let's see our training data.\n",
    "train_data.describe().show()\n",
    "\n",
    "# And our testing data.\n",
    "test_data.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "Now we can create a Linear Regression Model instance. Because the feature column is named 'features', we don't have to worry about it. However, as the labelCol isn't the default name, we have to specify it's name (medv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-0.08768171995287691,0.04156810439822088,0.03485554793084419,4.877901500391077,-18.10717650016799,3.396530513243429,-0.003485201766661757,-1.3459790348524527,0.24829628108813098,-0.009987236990479436,-0.9576820003039361,0.005596340757275696,-0.5303137617612333]\n",
      "Intercept: 39.84588018015844\n",
      "\n",
      "RMSE: 4.78101882094623\n",
      "R2: 0.7204588386054254\n"
     ]
    }
   ],
   "source": [
    "# Importing the LR package.\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Instantiate the instance.\n",
    "lr = LinearRegression(featuresCol='features', labelCol='medv')\n",
    "\n",
    "# Fit the training data.\n",
    "lr_model = lr.fit(train_data)\n",
    "\n",
    "# Print the coefficients.\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "\n",
    "# Print the intercept.\n",
    "print(\"Intercept: \" + str(lr_model.intercept) + \"\\n\")\n",
    "\n",
    "# Summarise the model and print out some evaluation metrics.\n",
    "training_summary = lr_model.summary\n",
    "\n",
    "# Print RMSE. \n",
    "print(\"RMSE: \" + str(training_summary.rootMeanSquaredError))\n",
    "\n",
    "# Print R2.\n",
    "print(\"R2: \" + str(training_summary.r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|              medv|\n",
      "+-------+------------------+\n",
      "|  count|               347|\n",
      "|   mean|22.520461095100888|\n",
      "| stddev| 9.055746543025418|\n",
      "|    min|               5.0|\n",
      "|    max|              50.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE measures the differences between predicted values and actual values. However, RMSE alone is meaningless until we compare with the actual \"medv\" value, such as mean, min and max. After such comparison, our RMSE looks pretty good.\n",
    "\n",
    "R2 indicates that our model can explain approximately 70% of the variability in median house value (medv)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model using the Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test data: 4.626537055363597\n",
      "R2 on test data: 0.7626967626458543\n"
     ]
    }
   ],
   "source": [
    "# Let's evaluate the model against the test data.\n",
    "test_results = lr_model.evaluate(test_data)\n",
    "\n",
    "# And print the RMSE/R2. As expected, our RMSE and R2 are slightly worse when applying the testing set.\n",
    "print(\"RMSE on test data: \" + str(test_results.rootMeanSquaredError))\n",
    "print(\"R2 on test data: \" + str(test_results.r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good job on finishing! But there's still a huge amount of complexity yet to be discussed. When you use PySpark with your own dataset, be sure to look through the documentation, understand which parameters you can use and do your best to figure out what they actually do. \n",
    "\n",
    "These tutorials are designed to be finished within a few hours, but it will take much more time, practice and patience before you can call yourself an expert!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
